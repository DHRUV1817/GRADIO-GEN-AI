import os
import time
from datetime import datetime
import gradio as gr
from dotenv import load_dotenv
from groq import Groq
from typing import List, Tuple, Generator
import logging
from dataclasses import dataclass, field
from enum import Enum
from functools import wraps

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Initialize Groq client
load_dotenv()
client = Groq(api_key=os.environ.get("GROQ_API_KEY"))

# Research-Based Implementation: Tree of Thoughts + Constitutional AI + Validator Agent


class ReasoningMode(Enum):
    """Research-aligned reasoning methodologies"""
    TREE_OF_THOUGHTS = "Tree of Thoughts (ToT)"
    CHAIN_OF_THOUGHT = "Chain of Thought (CoT)"
    SELF_CONSISTENCY = "Self-Consistency Sampling"
    REFLEXION = "Reflexion + Self-Correction"


@dataclass
class ConversationMetrics:
    """Enhanced metrics tracking"""
    reasoning_depth: int = 0
    self_corrections: int = 0
    confidence_score: float = 0.0
    inference_time: float = 0.0
    tokens_used: int = 0
    reasoning_paths_explored: int = 0
    last_updated: str = field(default_factory=lambda: datetime.now().strftime("%H:%M:%S"))


def error_handler(func):
    """Decorator for robust error handling"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger.error(f"Error in {func.__name__}: {str(e)}")
            return f"‚ö†Ô∏è **System Error:** {str(e)}\n\nPlease check your API key or try again."
    return wrapper


class AdvancedReasoner:
    """Enhanced Tree of Thoughts with Validator Agent (Haji et al., 2024)"""
    
    SYSTEM_PROMPTS = {
        ReasoningMode.TREE_OF_THOUGHTS: """You are an advanced reasoning system using Tree of Thoughts methodology.
Explore multiple reasoning paths systematically before converging on the best solution.
Always show your thought process explicitly.""",
        
        ReasoningMode.CHAIN_OF_THOUGHT: """You are a systematic problem solver using Chain of Thought reasoning.
Break down complex problems into clear, logical steps with explicit reasoning.""",
        
        ReasoningMode.SELF_CONSISTENCY: """You are a consistency-focused reasoning system.
Generate multiple independent solutions and identify the most consistent answer.""",
        
        ReasoningMode.REFLEXION: """You are a self-reflective AI system.
Solve problems, critique your own reasoning, and refine your solutions iteratively."""
    }
    
    def __init__(self):
        self.metrics = ConversationMetrics()
        self.conversation_history: List[dict] = []
        
    def build_reasoning_prompt(self, query: str, mode: ReasoningMode) -> str:
        """Generate enhanced reasoning prompts based on mode"""
        
        templates = {
            ReasoningMode.TREE_OF_THOUGHTS: f"""
üå≥ **Tree of Thoughts Analysis**

Problem: {query}

**Exploration Phase:**
PATH A (Analytical): [Examine from first principles]
PATH B (Alternative): [Consider different angle]
PATH C (Synthesis): [Integrate insights]

**Evaluation Phase:**
- Assess each path's validity
- Identify strongest reasoning chain
- Converge on optimal solution

**Final Solution:** [Most robust answer with justification]""",

            ReasoningMode.CHAIN_OF_THOUGHT: f"""
üîó **Step-by-Step Reasoning**

Problem: {query}

Step 1: Understand the question
Step 2: Identify key components
Step 3: Apply relevant logic/principles
Step 4: Derive solution
Step 5: Validate and verify

Final Answer: [Clear, justified conclusion]""",

            ReasoningMode.SELF_CONSISTENCY: f"""
üéØ **Multi-Path Consistency Check**

Problem: {query}

**Attempt 1:** [First independent solution]
**Attempt 2:** [Alternative approach]
**Attempt 3:** [Third perspective]

**Consensus:** [Most consistent answer across attempts]""",

            ReasoningMode.REFLEXION: f"""
üîç **Reflexion with Self-Correction**

Problem: {query}

**Initial Solution:** [First attempt]

**Self-Critique:**
- Assumptions made?
- Logical flaws?
- Missing elements?

**Refined Solution:** [Improved answer based on reflection]"""
        }
        
        return templates.get(mode, query)
    
    @error_handler
    def generate_response(
        self,
        query: str,
        history: List[Tuple[str, str]],
        model: str,
        reasoning_mode: ReasoningMode,
        enable_critique: bool,
        temperature: float,
        max_tokens: int
    ) -> Generator[str, None, None]:
        """Generate response with enhanced reasoning and validation"""
        
        start_time = time.time()
        self.metrics.reasoning_paths_explored = 0
        
        # Build enhanced prompt
        enhanced_query = self.build_reasoning_prompt(query, reasoning_mode)
        
        # Construct messages with context
        messages = [
            {"role": "system", "content": self.SYSTEM_PROMPTS[reasoning_mode]}
        ]
        
        # Add conversation context (last 5 exchanges)
        for user_msg, ai_msg in history[-5:]:
            messages.append({"role": "user", "content": user_msg})
            messages.append({"role": "assistant", "content": ai_msg})
        
        messages.append({"role": "user", "content": enhanced_query})
        
        # Phase 1: Initial reasoning
        stream = client.chat.completions.create(
            messages=messages,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            stream=True,
        )
        
        full_response = ""
        for chunk in stream:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                full_response += content
                self.metrics.tokens_used += 1
                yield full_response
        
        # Count reasoning depth
        self.metrics.reasoning_depth = (
            full_response.count("Step") + 
            full_response.count("PATH") +
            full_response.count("Attempt")
        )
        
        # Phase 2: Constitutional AI Self-Critique (if enabled)
        if enable_critique and len(full_response) > 150:
            critique_prompt = f"""
**Validation Check:**
Review the previous response for:
1. Factual accuracy
2. Logical consistency  
3. Completeness
4. Potential biases or errors

Provide brief validation or corrections if needed."""
            
            messages.append({"role": "assistant", "content": full_response})
            messages.append({"role": "user", "content": critique_prompt})
            
            critique_stream = client.chat.completions.create(
                messages=messages,
                model=model,
                temperature=temperature * 0.7,  # Lower temperature for critique
                max_tokens=max_tokens // 3,
                stream=True,
            )
            
            full_response += "\n\n---\n### üîç Validation & Self-Critique\n"
            for chunk in critique_stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_response += content
                    yield full_response
            
            self.metrics.self_corrections += 1
        
        # Update metrics
        self.metrics.inference_time = time.time() - start_time
        self.metrics.last_updated = datetime.now().strftime("%H:%M:%S")
        self.metrics.confidence_score = min(95.0, 60.0 + (self.metrics.reasoning_depth * 5))
        
        yield full_response


# Initialize system
reasoner = AdvancedReasoner()


# Modern UI with improved styling
CUSTOM_CSS = """
.research-header {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    padding: 2rem;
    border-radius: 12px;
    color: white;
    margin-bottom: 1.5rem;
    box-shadow: 0 4px 6px rgba(0,0,0,0.1);
}

.metrics-card {
    background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    border-left: 5px solid #667eea;
    padding: 1rem;
    border-radius: 8px;
    margin: 0.5rem 0;
    font-family: 'Courier New', monospace;
}

.badge {
    background: rgba(255,255,255,0.2);
    color: white;
    padding: 0.3rem 0.8rem;
    border-radius: 20px;
    font-size: 0.85rem;
    margin: 0.25rem;
    display: inline-block;
}

.status-active { color: #10b981; font-weight: bold; }
.status-error { color: #ef4444; font-weight: bold; }
"""


# Gradio Interface
with gr.Blocks(
    theme=gr.themes.Soft(
        primary_hue="purple",
        secondary_hue="blue",
        font=gr.themes.GoogleFont("Inter")
    ),
    css=CUSTOM_CSS,
    title="üî¨ Advanced AI Reasoning System"
) as demo:
    
    gr.HTML("""
    <div class="research-header">
        <h1>üî¨ Advanced AI Reasoning Research System</h1>
        <p style="font-size: 1.1rem; margin: 0.5rem 0;">
            <strong>Research Implementation:</strong> Tree of Thoughts + Constitutional AI + Multi-Agent Validation
        </p>
        <div style="margin-top: 1rem;">
            <span class="badge">üìÑ Yao et al. 2023 - Tree of Thoughts</span>
            <span class="badge">üìÑ Bai et al. 2022 - Constitutional AI</span>
            <span class="badge">üìÑ Haji et al. 2024 - Validator Agent</span>
        </div>
    </div>
    """)
    
    with gr.Row():
        gr.Markdown("""
        ### üéØ System Capabilities
        - **Multi-Path Reasoning:** Explores diverse solution pathways before converging
        - **Self-Validation:** Constitutional AI ensures accuracy and safety
        - **Adaptive Learning:** Improves reasoning quality through self-reflection
        """)
    
    with gr.Row():
        with gr.Column(scale=3):
            chatbot = gr.Chatbot(
                label="üí¨ Reasoning Workspace",
                height=550,
                show_copy_button=True,
                show_label=True,
                avatar_images=(
                    "https://api.dicebear.com/7.x/avataaars/svg?seed=User",
                    "https://api.dicebear.com/7.x/bottts/svg?seed=AI"
                ),
                bubble_full_width=False
            )
            
            with gr.Row():
                msg = gr.Textbox(
                    placeholder="üí° Enter your complex problem or research question...",
                    label="Query Input",
                    lines=3,
                    scale=4
                )
            
            with gr.Row():
                submit_btn = gr.Button("üöÄ Process", variant="primary", scale=2)
                clear_btn = gr.Button("üóëÔ∏è Clear", scale=1)
        
        with gr.Column(scale=1):
            gr.Markdown("### ‚öôÔ∏è Configuration")
            
            reasoning_mode = gr.Radio(
                choices=[mode.value for mode in ReasoningMode],
                value=ReasoningMode.TREE_OF_THOUGHTS.value,
                label="üß† Reasoning Method",
                info="Select research-backed approach"
            )
            
            enable_critique = gr.Checkbox(
                label="üîç Enable Self-Critique",
                value=True,
                info="Applies Constitutional AI validation"
            )
            
            model = gr.Dropdown(
                choices=[
                    "llama-3.3-70b-versatile",
                    "deepseek-r1-distill-llama-70b",
                    "mixtral-8x7b-32768",
                    "llama-3.1-70b-versatile"
                ],
                value="llama-3.3-70b-versatile",
                label="ü§ñ Model"
            )
            
            with gr.Accordion("üéõÔ∏è Advanced Parameters", open=False):
                temperature = gr.Slider(
                    0.0, 1.5, value=0.7, step=0.1,
                    label="üå°Ô∏è Temperature",
                    info="Creativity vs. determinism"
                )
                max_tokens = gr.Slider(
                    1000, 8000, value=4000, step=500,
                    label="üìè Max Tokens"
                )
            
            gr.Markdown("### üìä Live Metrics")
            metrics_display = gr.Markdown(
                """<div class="metrics-card">
                <strong>‚è±Ô∏è Inference Time:</strong> 0.0s<br>
                <strong>üß† Reasoning Depth:</strong> 0 steps<br>
                <strong>‚úÖ Self-Corrections:</strong> 0<br>
                <strong>üéØ Confidence:</strong> 0%<br>
                <strong>üìç Status:</strong> <span class="status-active">Ready</span>
                </div>"""
            )
            
            gr.Markdown("""
            ### üìö References
            - [Tree of Thoughts](https://arxiv.org/abs/2305.10601) (Yao et al., 2023)
            - [Constitutional AI](https://arxiv.org/abs/2212.08073) (Bai et al., 2022)
            - [MA-ToT Validator](https://arxiv.org/abs/2409.11527) (Haji et al., 2024)
            """)
    
    def process_message(message, history, mode, critique, model_name, temp, tokens):
        """Process user query with reasoning"""
        if not message.strip():
            return history, update_metrics()
        
        mode_enum = ReasoningMode(mode)
        
        # Stream response
        for response in reasoner.generate_response(
            message, history, model_name, mode_enum, critique, temp, tokens
        ):
            yield history + [(message, response)], update_metrics()
    
    def update_metrics():
        """Update metrics display with current values"""
        m = reasoner.metrics
        status = '<span class="status-active">Active</span>' if m.tokens_used > 0 else '<span>Ready</span>'
        
        return f"""<div class="metrics-card">
        <strong>‚è±Ô∏è Inference Time:</strong> {m.inference_time:.2f}s<br>
        <strong>üß† Reasoning Depth:</strong> {m.reasoning_depth} steps<br>
        <strong>‚úÖ Self-Corrections:</strong> {m.self_corrections}<br>
        <strong>üéØ Confidence:</strong> {m.confidence_score:.1f}%<br>
        <strong>üìç Status:</strong> {status}<br>
        <strong>üïê Last Updated:</strong> {m.last_updated}
        </div>"""
    
    def reset_chat():
        """Reset conversation and metrics"""
        reasoner.metrics = ConversationMetrics()
        return None, update_metrics()
    
    # Event handlers
    msg.submit(
        process_message,
        [msg, chatbot, reasoning_mode, enable_critique, model, temperature, max_tokens],
        [chatbot, metrics_display]
    ).then(lambda: "", None, [msg])
    
    submit_btn.click(
        process_message,
        [msg, chatbot, reasoning_mode, enable_critique, model, temperature, max_tokens],
        [chatbot, metrics_display]
    ).then(lambda: "", None, [msg])
    
    clear_btn.click(reset_chat, None, [chatbot, metrics_display])


if __name__ == "__main__":
    demo.launch(
        share=False,
        server_name="0.0.0.0",
        server_port=7860,
        show_error=True,
        show_api=False
    )
